{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 553928.00 MB\n",
      "Memory usage after optimization is: 147028.00 MB\n",
      "Decreased by 73.5%\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "\n",
    "    start_mem = df.memory_usage().sum() \n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() \n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "data = pd.read_csv('data1.csv', sep=',')\n",
    "data = reduce_mem_usage(data)\n",
    "\n",
    "endl_name = ['x77', 'x30', 'x33', 'x61', 'x26', 'x2', 'x274', 'x6', 'x28', 'x54', 'x162', 'x320', 'x315', 'x245', 'x273', 'x191', 'x169', 'x130', 'x182', 'x317', 'x123', 'x4', 'x174', 'x16']\n",
    "\n",
    "X = data[endl_name]\n",
    "Y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001B[0m 1       \u001B[0m | \u001B[0m 0.9561  \u001B[0m | \u001B[0m 0.5771  \u001B[0m | \u001B[0m 0.0354  \u001B[0m | \u001B[0m 7.352   \u001B[0m | \u001B[0m 68.55   \u001B[0m | \u001B[0m 177.8   \u001B[0m | \u001B[0m 0.6256  \u001B[0m |\n",
      "| \u001B[0m 2       \u001B[0m | \u001B[0m 0.9536  \u001B[0m | \u001B[0m 0.8792  \u001B[0m | \u001B[0m 0.1159  \u001B[0m | \u001B[0m 9.178   \u001B[0m | \u001B[0m 47.84   \u001B[0m | \u001B[0m 134.9   \u001B[0m | \u001B[0m 0.9145  \u001B[0m |\n",
      "| \u001B[0m 3       \u001B[0m | \u001B[0m 0.954   \u001B[0m | \u001B[0m 0.6493  \u001B[0m | \u001B[0m 0.01596 \u001B[0m | \u001B[0m 11.14   \u001B[0m | \u001B[0m 90.54   \u001B[0m | \u001B[0m 305.8   \u001B[0m | \u001B[0m 0.7696  \u001B[0m |\n",
      "| \u001B[95m 4       \u001B[0m | \u001B[95m 0.9564  \u001B[0m | \u001B[95m 0.8322  \u001B[0m | \u001B[95m 0.1305  \u001B[0m | \u001B[95m 7.241   \u001B[0m | \u001B[95m 4.611   \u001B[0m | \u001B[95m 166.1   \u001B[0m | \u001B[95m 0.9397  \u001B[0m |\n",
      "| \u001B[0m 5       \u001B[0m | \u001B[0m 0.9508  \u001B[0m | \u001B[0m 0.5339  \u001B[0m | \u001B[0m 0.08013 \u001B[0m | \u001B[0m 4.386   \u001B[0m | \u001B[0m 11.44   \u001B[0m | \u001B[0m 133.5   \u001B[0m | \u001B[0m 0.5435  \u001B[0m |\n",
      "| \u001B[0m 6       \u001B[0m | \u001B[0m 0.9498  \u001B[0m | \u001B[0m 0.9228  \u001B[0m | \u001B[0m 0.1729  \u001B[0m | \u001B[0m 9.692   \u001B[0m | \u001B[0m 4.014   \u001B[0m | \u001B[0m 499.7   \u001B[0m | \u001B[0m 0.9463  \u001B[0m |\n",
      "| \u001B[0m 7       \u001B[0m | \u001B[0m 0.9555  \u001B[0m | \u001B[0m 0.536   \u001B[0m | \u001B[0m 0.09682 \u001B[0m | \u001B[0m 5.987   \u001B[0m | \u001B[0m 99.02   \u001B[0m | \u001B[0m 101.5   \u001B[0m | \u001B[0m 0.6156  \u001B[0m |\n",
      "| \u001B[0m 8       \u001B[0m | \u001B[0m 0.9511  \u001B[0m | \u001B[0m 0.7756  \u001B[0m | \u001B[0m 0.0915  \u001B[0m | \u001B[0m 12.5    \u001B[0m | \u001B[0m 98.03   \u001B[0m | \u001B[0m 106.3   \u001B[0m | \u001B[0m 0.5547  \u001B[0m |\n",
      "| \u001B[0m 9       \u001B[0m | \u001B[0m 0.9522  \u001B[0m | \u001B[0m 0.6393  \u001B[0m | \u001B[0m 0.1889  \u001B[0m | \u001B[0m 13.98   \u001B[0m | \u001B[0m 98.86   \u001B[0m | \u001B[0m 103.4   \u001B[0m | \u001B[0m 0.7621  \u001B[0m |\n",
      "| \u001B[0m 10      \u001B[0m | \u001B[0m 0.9472  \u001B[0m | \u001B[0m 0.905   \u001B[0m | \u001B[0m 0.1755  \u001B[0m | \u001B[0m 3.975   \u001B[0m | \u001B[0m 2.42    \u001B[0m | \u001B[0m 324.7   \u001B[0m | \u001B[0m 0.7348  \u001B[0m |\n",
      "| \u001B[0m 11      \u001B[0m | \u001B[0m 0.9454  \u001B[0m | \u001B[0m 0.6007  \u001B[0m | \u001B[0m 0.1951  \u001B[0m | \u001B[0m 3.4     \u001B[0m | \u001B[0m 99.81   \u001B[0m | \u001B[0m 494.2   \u001B[0m | \u001B[0m 0.6961  \u001B[0m |\n",
      "| \u001B[0m 12      \u001B[0m | \u001B[0m 0.9541  \u001B[0m | \u001B[0m 0.8525  \u001B[0m | \u001B[0m 0.08137 \u001B[0m | \u001B[0m 4.032   \u001B[0m | \u001B[0m 99.81   \u001B[0m | \u001B[0m 204.6   \u001B[0m | \u001B[0m 0.9714  \u001B[0m |\n",
      "| \u001B[0m 13      \u001B[0m | \u001B[0m 0.9451  \u001B[0m | \u001B[0m 0.5274  \u001B[0m | \u001B[0m 0.1557  \u001B[0m | \u001B[0m 14.88   \u001B[0m | \u001B[0m 4.216   \u001B[0m | \u001B[0m 239.8   \u001B[0m | \u001B[0m 0.5383  \u001B[0m |\n",
      "| \u001B[0m 14      \u001B[0m | \u001B[0m 0.9556  \u001B[0m | \u001B[0m 0.9922  \u001B[0m | \u001B[0m 0.03202 \u001B[0m | \u001B[0m 3.291   \u001B[0m | \u001B[0m 99.89   \u001B[0m | \u001B[0m 402.4   \u001B[0m | \u001B[0m 0.922   \u001B[0m |\n",
      "| \u001B[0m 15      \u001B[0m | \u001B[0m 0.9505  \u001B[0m | \u001B[0m 0.8978  \u001B[0m | \u001B[0m 0.149   \u001B[0m | \u001B[0m 14.88   \u001B[0m | \u001B[0m 48.83   \u001B[0m | \u001B[0m 432.1   \u001B[0m | \u001B[0m 0.9711  \u001B[0m |\n",
      "| \u001B[0m 16      \u001B[0m | \u001B[0m 0.9504  \u001B[0m | \u001B[0m 0.5744  \u001B[0m | \u001B[0m 0.1431  \u001B[0m | \u001B[0m 3.004   \u001B[0m | \u001B[0m 33.17   \u001B[0m | \u001B[0m 445.4   \u001B[0m | \u001B[0m 0.8168  \u001B[0m |\n",
      "| \u001B[0m 17      \u001B[0m | \u001B[0m 0.9551  \u001B[0m | \u001B[0m 0.8034  \u001B[0m | \u001B[0m 0.06231 \u001B[0m | \u001B[0m 3.221   \u001B[0m | \u001B[0m 35.84   \u001B[0m | \u001B[0m 194.1   \u001B[0m | \u001B[0m 0.9705  \u001B[0m |\n",
      "| \u001B[0m 18      \u001B[0m | \u001B[0m 0.9536  \u001B[0m | \u001B[0m 0.8691  \u001B[0m | \u001B[0m 0.08277 \u001B[0m | \u001B[0m 3.178   \u001B[0m | \u001B[0m 95.25   \u001B[0m | \u001B[0m 150.3   \u001B[0m | \u001B[0m 0.9887  \u001B[0m |\n",
      "| \u001B[0m 19      \u001B[0m | \u001B[0m 0.9529  \u001B[0m | \u001B[0m 0.6435  \u001B[0m | \u001B[0m 0.1237  \u001B[0m | \u001B[0m 3.09    \u001B[0m | \u001B[0m 95.13   \u001B[0m | \u001B[0m 354.6   \u001B[0m | \u001B[0m 0.9263  \u001B[0m |\n",
      "| \u001B[0m 20      \u001B[0m | \u001B[0m 0.9506  \u001B[0m | \u001B[0m 0.7517  \u001B[0m | \u001B[0m 0.1997  \u001B[0m | \u001B[0m 14.36   \u001B[0m | \u001B[0m 99.43   \u001B[0m | \u001B[0m 402.2   \u001B[0m | \u001B[0m 0.8061  \u001B[0m |\n",
      "| \u001B[0m 21      \u001B[0m | \u001B[0m 0.9555  \u001B[0m | \u001B[0m 0.9957  \u001B[0m | \u001B[0m 0.0373  \u001B[0m | \u001B[0m 3.614   \u001B[0m | \u001B[0m 98.22   \u001B[0m | \u001B[0m 281.8   \u001B[0m | \u001B[0m 0.9183  \u001B[0m |\n",
      "| \u001B[0m 22      \u001B[0m | \u001B[0m 0.9543  \u001B[0m | \u001B[0m 0.9543  \u001B[0m | \u001B[0m 0.1338  \u001B[0m | \u001B[0m 3.249   \u001B[0m | \u001B[0m 58.88   \u001B[0m | \u001B[0m 101.5   \u001B[0m | \u001B[0m 0.9587  \u001B[0m |\n",
      "| \u001B[0m 23      \u001B[0m | \u001B[0m 0.951   \u001B[0m | \u001B[0m 0.9308  \u001B[0m | \u001B[0m 0.1407  \u001B[0m | \u001B[0m 3.037   \u001B[0m | \u001B[0m 58.37   \u001B[0m | \u001B[0m 204.2   \u001B[0m | \u001B[0m 0.7296  \u001B[0m |\n",
      "| \u001B[0m 24      \u001B[0m | \u001B[0m 0.9548  \u001B[0m | \u001B[0m 0.8947  \u001B[0m | \u001B[0m 0.0491  \u001B[0m | \u001B[0m 14.04   \u001B[0m | \u001B[0m 3.015   \u001B[0m | \u001B[0m 423.2   \u001B[0m | \u001B[0m 0.5005  \u001B[0m |\n",
      "| \u001B[0m 25      \u001B[0m | \u001B[0m 0.9558  \u001B[0m | \u001B[0m 0.714   \u001B[0m | \u001B[0m 0.01619 \u001B[0m | \u001B[0m 5.138   \u001B[0m | \u001B[0m 3.263   \u001B[0m | \u001B[0m 399.7   \u001B[0m | \u001B[0m 0.8191  \u001B[0m |\n",
      "| \u001B[0m 26      \u001B[0m | \u001B[0m 0.9555  \u001B[0m | \u001B[0m 0.7299  \u001B[0m | \u001B[0m 0.02537 \u001B[0m | \u001B[0m 3.738   \u001B[0m | \u001B[0m 2.766   \u001B[0m | \u001B[0m 429.8   \u001B[0m | \u001B[0m 0.9656  \u001B[0m |\n",
      "| \u001B[0m 27      \u001B[0m | \u001B[0m 0.9459  \u001B[0m | \u001B[0m 0.7279  \u001B[0m | \u001B[0m 0.1868  \u001B[0m | \u001B[0m 14.87   \u001B[0m | \u001B[0m 30.58   \u001B[0m | \u001B[0m 170.3   \u001B[0m | \u001B[0m 0.9988  \u001B[0m |\n",
      "| \u001B[0m 28      \u001B[0m | \u001B[0m 0.9551  \u001B[0m | \u001B[0m 0.508   \u001B[0m | \u001B[0m 0.09154 \u001B[0m | \u001B[0m 3.724   \u001B[0m | \u001B[0m 3.494   \u001B[0m | \u001B[0m 201.6   \u001B[0m | \u001B[0m 0.7127  \u001B[0m |\n",
      "| \u001B[0m 29      \u001B[0m | \u001B[0m 0.9556  \u001B[0m | \u001B[0m 0.5046  \u001B[0m | \u001B[0m 0.02278 \u001B[0m | \u001B[0m 3.059   \u001B[0m | \u001B[0m 71.54   \u001B[0m | \u001B[0m 145.8   \u001B[0m | \u001B[0m 0.5356  \u001B[0m |\n",
      "| \u001B[0m 30      \u001B[0m | \u001B[0m 0.9492  \u001B[0m | \u001B[0m 0.7063  \u001B[0m | \u001B[0m 0.1902  \u001B[0m | \u001B[0m 3.088   \u001B[0m | \u001B[0m 92.65   \u001B[0m | \u001B[0m 102.7   \u001B[0m | \u001B[0m 0.7495  \u001B[0m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "# xx_train, xx_test, yy_train, yy_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "def xgb_cv(n_estimators, max_depth, subsample, colsample_bytree, learning_rate, min_child_weight):\n",
    "    res = cross_val_score( \n",
    "        XGBRegressor(n_estimators=int(n_estimators), \n",
    "                     max_depth=int(max_depth),\n",
    "                     learning_rate=learning_rate, \n",
    "#                      scale_pos_weight=1.0,\n",
    "#                      base_score=0.5, \n",
    "                     random_state=10, \n",
    "                     subsample=float(subsample),\n",
    "                     colsample_bytree = float(colsample_bytree),\n",
    "#                      min_child_weight = int(min_child_weight)\n",
    "                     \n",
    "        ),\n",
    "        X, Y, scoring=make_scorer(mean_squared_error)\n",
    "    ).mean()\n",
    "    return 1-res\n",
    "\n",
    "gbdt_op = BayesianOptimization(\n",
    "        xgb_cv,\n",
    "       {\n",
    "           \n",
    "            'n_estimators': (100, 500),\n",
    "            'max_depth': (3, 15),\n",
    "           \n",
    "            'subsample': (0.5, 1),\n",
    "            'colsample_bytree': (0.5, 1),\n",
    "            'learning_rate':(0.01, 0.2),\n",
    "            'min_child_weight':(2,100)\n",
    "#             'min_child_weight': (0, 20),\n",
    "#             'max_delta_step': (0, 2),\n",
    "        },\n",
    "        random_state=66,\n",
    "    )\n",
    "\n",
    "gbdt_op.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.9563555765897036,\n",
       " 'params': {'colsample_bytree': 0.8321637581704533,\n",
       "  'learning_rate': 0.13047078350081956,\n",
       "  'max_depth': 7.241033617708029,\n",
       "  'min_child_weight': 4.6109662584884,\n",
       "  'n_estimators': 166.1159358189439,\n",
       "  'subsample': 0.9396594956925226}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_op.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.6, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.13, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=66, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=0.7, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgbmodel = XGBRegressor(n_estimators=424, \n",
    "#                      max_depth=14,\n",
    "#                      learning_rate= 0.15354501758169445, \n",
    "#                      random_state=10, \n",
    "#                      subsample=0.8245215977200513,\n",
    "#                      colsample_bytree = 0.8109203086197454）\n",
    "                        \n",
    "xgbmodel = XGBRegressor(n_estimators=100, max_depth=2,\n",
    "                     learning_rate=0.13, \n",
    "                     random_state=66, subsample=0.7,\n",
    "                     colsample_bytree = 0.6)\n",
    "# xgbmodel.fit(x_train,y_train)\n",
    "# xx_train, xx_test, yy_train, yy_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "xgbmodel.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= xgbmodel.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.014129029, 0.09144071)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y, y_pred), mean_absolute_error(Y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbmodel2 = XGBRegressor(n_estimators=166, max_depth=7,\n",
    "                     learning_rate=0.13, \n",
    "                     random_state=66, subsample=0.93,\n",
    "                     colsample_bytree = 0.83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = y_pred - Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11886555937279743"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(error**2).mean()**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3753949 ],\n",
       "       [1.2590351 ],\n",
       "       [1.303601  ],\n",
       "       [1.2804633 ],\n",
       "       [1.341224  ],\n",
       "       [1.3209068 ],\n",
       "       [1.3029152 ],\n",
       "       [1.3273654 ],\n",
       "       [1.3671188 ],\n",
       "       [1.3938401 ],\n",
       "       [1.2995529 ],\n",
       "       [1.4129889 ],\n",
       "       [1.3944073 ],\n",
       "       [1.3380663 ],\n",
       "       [1.5775281 ],\n",
       "       [1.4713745 ],\n",
       "       [1.309644  ],\n",
       "       [1.4339995 ],\n",
       "       [1.2985985 ],\n",
       "       [1.2679257 ],\n",
       "       [1.3407257 ],\n",
       "       [1.1758838 ],\n",
       "       [1.4165163 ],\n",
       "       [1.4423895 ],\n",
       "       [1.464776  ],\n",
       "       [1.4648402 ],\n",
       "       [1.4266336 ],\n",
       "       [1.3427565 ],\n",
       "       [1.3837293 ],\n",
       "       [1.3390483 ],\n",
       "       [1.3870273 ],\n",
       "       [1.3572204 ],\n",
       "       [1.0919614 ],\n",
       "       [1.057198  ],\n",
       "       [1.2064166 ],\n",
       "       [1.3623703 ],\n",
       "       [1.3425831 ],\n",
       "       [1.2996393 ],\n",
       "       [1.2571728 ],\n",
       "       [1.2932085 ],\n",
       "       [1.4180137 ],\n",
       "       [1.2559315 ],\n",
       "       [1.4409219 ],\n",
       "       [1.2180843 ],\n",
       "       [1.1851115 ],\n",
       "       [1.213416  ],\n",
       "       [1.2504911 ],\n",
       "       [1.2314823 ],\n",
       "       [1.0894463 ],\n",
       "       [1.0965405 ],\n",
       "       [1.2280781 ],\n",
       "       [1.3209631 ],\n",
       "       [1.1506782 ],\n",
       "       [1.3137128 ],\n",
       "       [1.3509353 ],\n",
       "       [1.3736157 ],\n",
       "       [1.1903125 ],\n",
       "       [1.3063622 ],\n",
       "       [1.4754483 ],\n",
       "       [1.3734164 ],\n",
       "       [1.4259664 ],\n",
       "       [1.589094  ],\n",
       "       [1.5669415 ],\n",
       "       [1.4629701 ],\n",
       "       [1.2058918 ],\n",
       "       [1.41314   ],\n",
       "       [1.3935242 ],\n",
       "       [1.4032303 ],\n",
       "       [1.5109065 ],\n",
       "       [1.6165156 ],\n",
       "       [1.5723318 ],\n",
       "       [1.4529455 ],\n",
       "       [1.4921422 ],\n",
       "       [1.3315003 ],\n",
       "       [1.4725163 ],\n",
       "       [1.6046023 ],\n",
       "       [1.4769647 ],\n",
       "       [1.4717116 ],\n",
       "       [1.5284308 ],\n",
       "       [1.3100917 ],\n",
       "       [1.2104095 ],\n",
       "       [1.4521766 ],\n",
       "       [1.5653887 ],\n",
       "       [1.5105518 ],\n",
       "       [1.2740141 ],\n",
       "       [1.4213197 ],\n",
       "       [1.099407  ],\n",
       "       [1.2553382 ],\n",
       "       [1.2487102 ],\n",
       "       [1.1916635 ],\n",
       "       [1.4152098 ],\n",
       "       [1.2763319 ],\n",
       "       [1.3157036 ],\n",
       "       [1.3299253 ],\n",
       "       [1.2934492 ],\n",
       "       [1.2824609 ],\n",
       "       [1.2020273 ],\n",
       "       [1.1561557 ],\n",
       "       [1.282273  ],\n",
       "       [1.3372333 ],\n",
       "       [1.5712365 ],\n",
       "       [1.310123  ],\n",
       "       [1.3152871 ],\n",
       "       [1.2760903 ],\n",
       "       [1.3216765 ],\n",
       "       [1.2802858 ],\n",
       "       [1.4169908 ],\n",
       "       [1.3839839 ],\n",
       "       [1.3099217 ],\n",
       "       [1.3305763 ],\n",
       "       [1.2729938 ],\n",
       "       [1.3590679 ],\n",
       "       [1.339257  ],\n",
       "       [1.37008   ],\n",
       "       [1.3377553 ],\n",
       "       [1.2807237 ],\n",
       "       [1.2282083 ],\n",
       "       [1.2604712 ],\n",
       "       [1.2339749 ],\n",
       "       [1.2066952 ],\n",
       "       [1.2764816 ],\n",
       "       [1.1812325 ],\n",
       "       [1.2408864 ],\n",
       "       [1.2514043 ],\n",
       "       [1.176969  ],\n",
       "       [1.2352111 ],\n",
       "       [1.1720743 ],\n",
       "       [1.2470014 ],\n",
       "       [0.96607536],\n",
       "       [1.3231401 ],\n",
       "       [1.485528  ],\n",
       "       [1.4504405 ],\n",
       "       [1.411533  ],\n",
       "       [1.4107614 ],\n",
       "       [1.6107638 ],\n",
       "       [1.5263915 ],\n",
       "       [1.5639442 ],\n",
       "       [1.5776998 ],\n",
       "       [1.0265921 ],\n",
       "       [1.3199791 ],\n",
       "       [1.1288197 ],\n",
       "       [0.37098545],\n",
       "       [1.4076905 ],\n",
       "       [1.3497026 ],\n",
       "       [1.4333854 ],\n",
       "       [1.4623885 ],\n",
       "       [1.3042114 ],\n",
       "       [1.3105218 ],\n",
       "       [1.614274  ],\n",
       "       [1.3297095 ],\n",
       "       [1.633037  ],\n",
       "       [1.5095999 ],\n",
       "       [1.5773039 ],\n",
       "       [1.3869783 ],\n",
       "       [1.3918967 ],\n",
       "       [1.3202691 ],\n",
       "       [1.3040617 ],\n",
       "       [1.284931  ],\n",
       "       [1.2093407 ],\n",
       "       [1.2138135 ],\n",
       "       [1.210825  ],\n",
       "       [1.2264163 ],\n",
       "       [1.1320055 ],\n",
       "       [1.0611393 ],\n",
       "       [1.1507822 ],\n",
       "       [1.1983255 ],\n",
       "       [0.7325366 ],\n",
       "       [1.082299  ],\n",
       "       [1.1015197 ],\n",
       "       [0.9797995 ],\n",
       "       [1.0125592 ],\n",
       "       [0.9669026 ],\n",
       "       [1.2999785 ],\n",
       "       [1.2032616 ],\n",
       "       [1.1291068 ],\n",
       "       [1.1857461 ],\n",
       "       [1.0103467 ],\n",
       "       [1.0898118 ],\n",
       "       [0.8491755 ],\n",
       "       [1.2585638 ],\n",
       "       [1.1539824 ],\n",
       "       [1.196368  ],\n",
       "       [1.0675108 ],\n",
       "       [0.9595549 ],\n",
       "       [0.5587219 ],\n",
       "       [1.0653594 ],\n",
       "       [1.0640826 ],\n",
       "       [1.1616879 ],\n",
       "       [1.3169718 ],\n",
       "       [1.087188  ],\n",
       "       [1.3384075 ],\n",
       "       [1.3619137 ],\n",
       "       [1.2630056 ],\n",
       "       [1.0555947 ],\n",
       "       [1.0235714 ],\n",
       "       [1.2442012 ],\n",
       "       [1.1639969 ],\n",
       "       [1.269673  ],\n",
       "       [1.2183675 ],\n",
       "       [1.2629311 ],\n",
       "       [1.2895573 ],\n",
       "       [1.2569051 ],\n",
       "       [1.297015  ],\n",
       "       [1.3184977 ],\n",
       "       [1.2579844 ],\n",
       "       [1.2787585 ],\n",
       "       [1.16805   ],\n",
       "       [1.2489147 ],\n",
       "       [1.085762  ],\n",
       "       [1.1343426 ],\n",
       "       [1.1059921 ],\n",
       "       [1.1554083 ],\n",
       "       [1.1500657 ],\n",
       "       [1.2044529 ],\n",
       "       [1.2176998 ],\n",
       "       [1.2031147 ],\n",
       "       [1.2695177 ],\n",
       "       [1.2649875 ],\n",
       "       [1.186553  ],\n",
       "       [1.079196  ],\n",
       "       [1.2029994 ],\n",
       "       [1.3157066 ],\n",
       "       [1.2949828 ],\n",
       "       [1.187743  ],\n",
       "       [1.2509195 ],\n",
       "       [1.2568455 ],\n",
       "       [1.3317591 ],\n",
       "       [1.2888738 ],\n",
       "       [1.2944312 ],\n",
       "       [1.2373035 ],\n",
       "       [1.1542182 ],\n",
       "       [1.222551  ],\n",
       "       [1.222551  ],\n",
       "       [1.2031858 ],\n",
       "       [1.1795044 ],\n",
       "       [1.184526  ],\n",
       "       [1.184526  ],\n",
       "       [1.1733162 ],\n",
       "       [1.1733162 ],\n",
       "       [1.1733162 ],\n",
       "       [1.0664992 ],\n",
       "       [1.0371296 ],\n",
       "       [1.0538521 ],\n",
       "       [1.2102354 ],\n",
       "       [1.2400527 ],\n",
       "       [1.1517472 ],\n",
       "       [1.2096162 ],\n",
       "       [1.2693857 ],\n",
       "       [1.2134155 ],\n",
       "       [1.1788064 ],\n",
       "       [1.1431106 ],\n",
       "       [1.1989653 ],\n",
       "       [1.1960497 ],\n",
       "       [1.1874754 ],\n",
       "       [1.2371163 ],\n",
       "       [1.2452978 ],\n",
       "       [1.1925238 ],\n",
       "       [1.206214  ],\n",
       "       [1.216672  ],\n",
       "       [1.2060935 ],\n",
       "       [1.2666025 ],\n",
       "       [1.2251964 ],\n",
       "       [1.2575786 ],\n",
       "       [1.303972  ],\n",
       "       [0.9234735 ],\n",
       "       [1.169768  ],\n",
       "       [1.2249033 ],\n",
       "       [1.277488  ],\n",
       "       [1.2345617 ],\n",
       "       [1.0620348 ],\n",
       "       [1.1957622 ],\n",
       "       [1.2026541 ],\n",
       "       [1.2124298 ],\n",
       "       [1.2186736 ],\n",
       "       [1.1881332 ],\n",
       "       [1.2286323 ],\n",
       "       [1.2368405 ],\n",
       "       [1.1127406 ],\n",
       "       [1.1659861 ],\n",
       "       [1.1426902 ],\n",
       "       [1.2322769 ],\n",
       "       [1.0990598 ],\n",
       "       [1.1429472 ],\n",
       "       [1.1462362 ],\n",
       "       [1.1591147 ],\n",
       "       [1.1248561 ],\n",
       "       [1.158718  ],\n",
       "       [1.1725252 ],\n",
       "       [1.2476027 ],\n",
       "       [1.0930405 ],\n",
       "       [1.2436306 ],\n",
       "       [0.7555368 ],\n",
       "       [1.1487309 ],\n",
       "       [1.114793  ],\n",
       "       [1.1822407 ],\n",
       "       [1.0650859 ],\n",
       "       [1.2094297 ],\n",
       "       [1.215033  ],\n",
       "       [1.1553153 ],\n",
       "       [1.188712  ],\n",
       "       [1.2298839 ],\n",
       "       [1.20264   ],\n",
       "       [1.373071  ],\n",
       "       [1.142139  ],\n",
       "       [1.1272113 ],\n",
       "       [1.1469674 ],\n",
       "       [1.1684437 ],\n",
       "       [1.2091668 ],\n",
       "       [1.1667154 ],\n",
       "       [1.2627943 ],\n",
       "       [1.1790128 ],\n",
       "       [1.1937494 ],\n",
       "       [1.275878  ],\n",
       "       [1.1636729 ],\n",
       "       [1.2088743 ],\n",
       "       [1.1709011 ],\n",
       "       [1.2103109 ],\n",
       "       [1.2296324 ],\n",
       "       [1.1926208 ],\n",
       "       [1.193218  ],\n",
       "       [1.2276026 ],\n",
       "       [1.2103138 ],\n",
       "       [1.285188  ],\n",
       "       [1.2924699 ],\n",
       "       [1.2870424 ]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2= xgbmodel2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.455699e-07"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.0845326e-07, 0.04700239)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(yy_train, y_train_pred2), mean_squared_error(yy_test, y_test_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}