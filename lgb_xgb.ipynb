{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 553928.00 MB\n",
      "Memory usage after optimization is: 147028.00 MB\n",
      "Decreased by 73.5%\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() \n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() \n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "data = pd.read_csv('data1.csv', sep=',')\n",
    "data = reduce_mem_usage(data)\n",
    "\n",
    "endl_name = ['x77', 'x30', 'x33', 'x61', 'x26', 'x2', 'x274', 'x6', 'x28', 'x54', 'x162', 'x320', 'x315', 'x245', 'x273', 'x191', 'x169', 'x130', 'x182', 'x317', 'x123', 'x4', 'x174', 'x16']\n",
    "\n",
    "X = data[endl_name]\n",
    "Y = data['y']\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import SGDRegressor, Lasso, Ridge\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestRegressor as rf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def single_model(clf, XX, YY, xx_test, yy_test, clf_name, class_num=1):\n",
    "    train = np.zeros((XX.shape[0], class_num))\n",
    "\n",
    "    if clf_name in ['sgd']:\n",
    "        print('MinMaxScaler...')\n",
    "        for col in endl_name:\n",
    "            ss = MinMaxScaler()\n",
    "            ss.fit(XX[[col]].values)\n",
    "            XX[col] = ss.transform(XX[[col]].values).flatten()\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(XX, YY, test_size=0.1, random_state=0)\n",
    "\n",
    "    if clf_name == \"lgb\":\n",
    "        train_matrix = clf.Dataset(x_train, label=y_train)\n",
    "        valid_matrix = clf.Dataset(x_test, label=y_test)\n",
    "        test_matrix = clf.Dataset(xx_test, label=yy_test)\n",
    "        data_matrix = clf.Dataset(XX, label=YY)\n",
    "\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'mse',\n",
    "            'min_child_weight': 5,\n",
    "            'num_leaves': 2 ** 8,\n",
    "            'feature_fraction': 0.5,\n",
    "            'bagging_fraction': 0.5,\n",
    "            'bagging_freq': 1,\n",
    "            'learning_rate': 0.001,\n",
    "            'seed': 2020\n",
    "        }\n",
    "\n",
    "        model = clf.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], verbose_eval=500,\n",
    "                          early_stopping_rounds=1000)\n",
    "        model2 = clf.train(params, data_matrix, model.best_iteration)\n",
    "#         val_pred = model.predict(x_test, num_iteration=model2.best_iteration).reshape(-1, 1)\n",
    "        yyyy_train__pred = model.predict(XX, num_iteration=model2.best_iteration).reshape(-1, 1)\n",
    "        yyyy_test_pred = model.predict(xx_test, num_iteration=model2.best_iteration).reshape(-1, 1)\n",
    "\n",
    "    if clf_name == \"xgb\":\n",
    "        train_matrix = clf.DMatrix(x_train, label=y_train, missing=np.nan)\n",
    "        valid_matrix = clf.DMatrix(x_test, label=y_test, missing=np.nan)\n",
    "        test_matrix = clf.DMatrix(xx_test, yy_test)\n",
    "        data_matrix = clf.DMatrix(XX, label=YY)\n",
    "        # test_matrix = clf.DMatrix(test_x, label=y_test, missing=np.nan)\n",
    "        params = {'booster': 'gbtree',\n",
    "                  'n_estimators': 1,\n",
    "                  'eval_metric': 'mae',\n",
    "                  'min_child_weight': 5,\n",
    "                  'max_depth': 5,\n",
    "                  'subsample': 0.8041,\n",
    "                  'colsample_bytree': 0.9289,\n",
    "                  'eta': 0.001,\n",
    "                  'seed': 2020,\n",
    "                  'nthread': 36,\n",
    "                  'silent': True,\n",
    "                  }\n",
    "\n",
    "        watchlist = [(train_matrix, 'train'), (valid_matrix, 'eval')]\n",
    "\n",
    "        model = clf.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=500,\n",
    "                          early_stopping_rounds=1000)\n",
    "#         val_pred = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit).reshape(-1, 1)\n",
    "        yyyy_train_pred = model.predict(data_matrix, ntree_limit=model.best_ntree_limit).reshape(-1, 1)\n",
    "        yyyy_test_pred = model.predict(test_matrix, ntree_limit=model.best_ntree_limit).reshape(-1, 1)\n",
    "\n",
    "    print(\"%s_mse_score:\" % clf_name, mean_squared_error(YY, yyyy_train_pred))\n",
    "\n",
    "    return mean_squared_error(YY, yyyy_train__pred), mean_squared_error(yy_test, yyyy_test_pred), yyyy_train__pred, yyyy_test_pred\n",
    "\n",
    "\n",
    "def lgb_model(x, y, xx, yy):\n",
    "    lgb_train_mse, lgb_test_mse, lgb_train_pred,  lgb_test_pred = single_model(lgb, x, y, xx, yy, \"lgb\")\n",
    "    return lgb_train_mse, lgb_test_mse, lgb_train_pred,  lgb_test_pred\n",
    "\n",
    "\n",
    "\n",
    "def xgb_model(x, y, xx, yy):\n",
    "    xgb_train_mse, xgb_test_mse, xgb_train_pred,  xgb_test_pred = single_model(xgb, x, y, xx, yy, \"xgb\")\n",
    "    return xgb_train_mse, xgb_test_mse, xgb_train_pred,  xgb_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx_train, xxx_test, yyy_train, yyy_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds\n",
      "[500]\ttraining's l2: 0.0454449\tvalid_1's l2: 0.0402616\n",
      "[1000]\ttraining's l2: 0.0416518\tvalid_1's l2: 0.0364825\n",
      "[1500]\ttraining's l2: 0.0390549\tvalid_1's l2: 0.0343262\n",
      "[2000]\ttraining's l2: 0.0370172\tvalid_1's l2: 0.0330873\n",
      "[2500]\ttraining's l2: 0.0352263\tvalid_1's l2: 0.0323414\n",
      "[3000]\ttraining's l2: 0.033738\tvalid_1's l2: 0.0318945\n",
      "[3500]\ttraining's l2: 0.0324321\tvalid_1's l2: 0.0317852\n",
      "[4000]\ttraining's l2: 0.031241\tvalid_1's l2: 0.0315489\n",
      "[4500]\ttraining's l2: 0.0301246\tvalid_1's l2: 0.0312829\n",
      "[5000]\ttraining's l2: 0.0291314\tvalid_1's l2: 0.0313613\n",
      "[5500]\ttraining's l2: 0.0282276\tvalid_1's l2: 0.0315205\n",
      "Early stopping, best iteration is:\n",
      "[4566]\ttraining's l2: 0.0299868\tvalid_1's l2: 0.0312747\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'yyyy_train_pred' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-14-a0276726bac2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mlgb_train_mse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlgb_test_mse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlgb_train_pred\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[0mlgb_test_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlgb_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mxxx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0myyy_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxxx_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0myyy_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mxgb_train_mse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxgb_test_mse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxgb_train_pred\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[0mxgb_test_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mxgb_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mxxx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0myyy_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxxx_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0myyy_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-12-9e4f2cdd6bb9>\u001B[0m in \u001B[0;36mlgb_model\u001B[1;34m(x, y, xx, yy)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mlgb_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0myy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 144\u001B[1;33m     \u001B[0mlgb_train_mse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlgb_test_mse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlgb_train_pred\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[0mlgb_test_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msingle_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlgb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0myy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"lgb\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    145\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mlgb_train_mse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlgb_test_mse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlgb_train_pred\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[0mlgb_test_pred\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-12-9e4f2cdd6bb9>\u001B[0m in \u001B[0;36msingle_model\u001B[1;34m(clf, XX, YY, xx_test, yy_test, clf_name, class_num)\u001B[0m\n\u001B[0;32m    136\u001B[0m         \u001B[0myyyy_test_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_matrix\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mntree_limit\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_ntree_limit\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 138\u001B[1;33m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"%s_mse_score:\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mclf_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmean_squared_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mYY\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0myyyy_train_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    139\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    140\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mmean_squared_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mYY\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0myyyy_train__pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmean_squared_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0myy_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0myyyy_test_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0myyyy_train__pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0myyyy_test_pred\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mUnboundLocalError\u001B[0m: local variable 'yyyy_train_pred' referenced before assignment"
     ]
    }
   ],
   "source": [
    "lgb_train_mse, lgb_test_mse, lgb_train_pred,  lgb_test_pred = lgb_model(xxx_train, yyy_train, xxx_test, yyy_test)\n",
    "\n",
    "xgb_train_mse, xgb_test_mse, xgb_train_pred,  xgb_test_pred = xgb_model(xxx_train, yyy_train, xxx_test, yyy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}